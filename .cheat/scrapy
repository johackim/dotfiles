Scrapy
===

An open source and collaborative framework for extracting the data you need from websites. In a fast, simple, yet extensible way. 

Commands
---

- `scrapy startproject <name_project>`
- `scrapy genspider <name_spider> <url_to_parse>`
- `scrapy crawl <name_spider>`
- `scrapy crawl <name_spider>` -o file.csv -t csv
- `scrapy crawl <name_spider>` -o file.json -t json
- `scrapy runspider file.py`
- `scrapy list`

Wait during download
---

Change DOWNLOAD_DELAY on settings.py

Store in a database
---

Use pipeline ?

Retry
---

RETRY_ENABLED = True
RETRY_TIMES = 2
RETRY_HTTP_CODES = [500, 502, 503, 504, 403]
https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#std:setting-RETRY_ENABLED

Avoid Banned
---

https://doc.scrapy.org/en/latest/topics/practices.html#avoiding-getting-banned

USER_AGENT = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.100 Safari/537.36"

https://github.com/fabienvauchelles/scrapoxy

Ressources
---

- [Scrapy & elasticsearch](http://blog.florian-hopf.de/2014/07/scrapy-and-elasticsearch.html)
- [Recursively Scraping Web Pages With Scrapy](http://mherman.org/blog/2012/11/08/recursively-scraping-web-pages-with-scrapy/)
- http://bigtheta.io/2016/02/08/web-scraping-in-python.html
- https://github.com/DormyMo/SpiderKeeper
- https://github.com/geekan/scrapy-examples
